
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Parallel Computing &#8212; Practical Data Science</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Defensive Programming" href="defensive_programming.html" />
    <link rel="prev" title="Solving Performance Issues" href="performance_solutions.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Parallel-Computing">
<h1>Parallel Computing<a class="headerlink" href="#Parallel-Computing" title="Permalink to this headline">¶</a></h1>
<p>Before you dive into this, let me just tell you the punchline of this entire page right up front: parallelism is the <strong>last tool</strong> you want to turn to for speed. It is <strong>not</strong> a silver bullet, it will generally take you <em>significant</em> time to implement, the speed improvements from parallelism are generally <strong>much</strong> smaller than what you get from other performance improvement methods (see <a class="reference internal" href="performance_understanding.html"><span class="doc">Understanding Performance</span></a> and <a class="reference internal" href="performance_solutions.html"><span class="doc">Performance
Solutions</span></a>), and the headaches of parallelizing code are many.</p>
<div class="section" id="What-is-Parallelism">
<h2>What <em>is</em> Parallelism<a class="headerlink" href="#What-is-Parallelism" title="Permalink to this headline">¶</a></h2>
<p>Parallelism is the process of:</p>
<ol class="arabic simple">
<li><p>taking a single problem,</p></li>
<li><p>breaking it into lots of smaller problems,</p></li>
<li><p>assigning those smaller problems to a number of processing cores that are able to operate independently, and</p></li>
<li><p>recombining the results.</p></li>
</ol>
<p>As this list shows, parallelism is not easy, and so not only does it take substantial developer time (the time it takes you to implement it), but there are computer-time costs to breaking down problems, distributing them, and recombining them, often limiting the returns you will see to parallelism.</p>
</div>
<div class="section" id="Why-is-Paralleism-important?">
<h2>Why is Paralleism important?<a class="headerlink" href="#Why-is-Paralleism-important?" title="Permalink to this headline">¶</a></h2>
<p>Given all that, why is parallelism all the rage?</p>
<p>The simple answer is that, when it comes to running a serial program (a problem where you run your code in sequence, one step at a time), processors stop getting faster in about the mid-2000s.</p>
<p>This might surprise you. Most of us have heard that Moore’s Law dictates that processors are doubling in performance every 18 months. The reality, however, is more complicated.</p>
<p>Moore’s law used to apply to a number of aspect of processors: the size of transistors, the number of transisters, and the speed that a processor executed serial code. But as shown in the figure below, processor frequency and the speed of serial execution stopped this pattern of doubling in the mid-2000s (serial execution has still been making small gains since then, but even that is iffy – those improvements are due to little hacks that only work when programs work in just the right way).</p>
<p><img alt="42-years-processor-trend" src="_images/42-years-processor-trend.png" /></p>
<p>Source: <a class="reference external" href="https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/">karlrupp.net</a></p>
<p>And so since chip makers have lost the ability to make their processors faster, they’ve turned to just giving us more and more processors in the form or more “cores”: components of chips that are capable of independent operation. And leveraging the availability of massive numbers of cores (either in single machines, or for huge datasets, across lots of computers) has become the only place left to go for performance!</p>
</div>
<div class="section" id="Limits-of-Parallelism">
<h2>Limits of Parallelism<a class="headerlink" href="#Limits-of-Parallelism" title="Permalink to this headline">¶</a></h2>
<p>OK, now let’s talk about the theoretical limits of parallelism.</p>
<p>The biggest problem with parallelism is that it’s very hard to break some problems into smaller pieces you can work on simultaneously. Some thing you do on computers are fundamentally <em>serial</em> / <em>sequential</em>, and thus cannot be broken up.</p>
<p>For example, suppose you want to simulate how weather evolves over time. The only way to simulate how weather will evolve on day 2 of your simulation is to wait till you’ve finished simulating day 1 so you can use those results as the starting point for your simulation in day 2. That means there’s no way to fully parallelize a weather simulation, since the results at time <span class="math notranslate nohighlight">\(t\)</span> will always depend on the results generated at time <span class="math notranslate nohighlight">\(t-1\)</span>.</p>
<p>To be clear, this is not to say there are <em>no</em> opportunities to speed up weather simulations – since you general run weather simulations over and over and then look at the <em>average</em> prediction, each separate simulation can be parallelized. But it does mean that <em>even if you had infinite processors</em>, you couldn’t bring the time it takes to simulate the weather down to zero because you’d have to finish simulating day 1 before you can simulate day 2.</p>
<div class="section" id="Amdahl’s-Law">
<h3>Amdahl’s Law<a class="headerlink" href="#Amdahl’s-Law" title="Permalink to this headline">¶</a></h3>
<p>The formalization of this idea is what’s called Amdahl’s Law, which gives the <em>theoretical</em> limits of parallelization. If <span class="math notranslate nohighlight">\(P\)</span> is the proportion of your algorithm that can be parallelized, the fundamental limit to the speed-up you can get from parallelization is given by:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{(1-P)+\frac{P}{N}}\]</div>
<p>Expressed graphically, this is:</p>
<p><img alt="amdahlslaw" src="_images/amdahlslaw.png" /></p>
<p>Source: <a class="reference external" href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Wikipedia</a></p>
<p>As this figure shows, even for a tasks that is <em>95% parallelizable</em>, the biggest possible performance gain you will ever get (with infinite cores), even ignoring any real-world overheads required to execute that parallelization is 20x.</p>
<p>Now, to be clear, that doesn’t mean there aren’t situations where the best strategy is parallelism. If you’ve exhausted all your other opportunities to speed up your code, parallelism may be all that’s left. And in data science, it’s not uncommon to have code that can be much more than 95% parallelizable – for example, if you need to run a simulation 1,000,000 times, and each run is relatively short, you can get close to 100% parallelizable. But the point is that parallelism is no silver bullet,
and it’s important to think hard about whether your problem is suited to parallelizing before you invest in trying to parallelize your code!</p>
</div>
</div>
<div class="section" id="Vocabulary">
<h2>Vocabulary<a class="headerlink" href="#Vocabulary" title="Permalink to this headline">¶</a></h2>
<p>The terms processor and core are often used interchangable among computer scientists to refer to “units capable of indepedent operation”. This can be confusing because most of us think of a “processor” as a single square piece of silicone material that is plugged into our motherboard (e.g. a Intel i9, or an Intel i7):</p>
<p><img alt="intel_chip" src="_images/intel_chip.jpg" /></p>
<p>But what most of us think of as processors today often have many cores (the Intel i9 on my laptop has 8 cores, each capable of working relatively independently). Here’s a labeled image of the inside of a core i7 processor with four distinct “cores”:</p>
<p><img alt="core_i7" src="_images/core_i7.gif" /></p>
<p>This gets even more confusing for two reasons:</p>
<p>First, many desktops have two seperate chips (i.e. two Intel i7s, or two Intel i9s), leading some people to call these multi-processor machines. :/</p>
<p>Second, many modern processors have a feature called “hyperthreading”, which is where two tasks can be assigned to the same individual core. That core can’t do both tasks at the same time, but it can try and switch between them efficiently. For example, if the first task stalls out while it’s waiting to get more data from memory (remember how <a class="reference internal" href="performance_understanding.html"><span class="doc">slow memory is</span></a>), the core can switch to working on the second task instead of just sitting around. This <em>can</em> offer
additional performance, but much less than actually having an actual additional independent core, and actual performance depends on the nature of the job being run (I’ve heard data science people say if two cores gets you 2x performance, then hyperthreading gets you about 1.25x performance, which seems roughly consistent with my experience. But again this depends <em>hugely</em> on the nature of the job you’re parallelizing).</p>
<p>Confusingly, though, the way hyperthreading manifests is by telling your operating system that you have two cores for every physical core on your computer. So for example, while my computer has only 8 physical cores, if I open Python and run:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>16
</pre></div>
</div>
</div>
<p>I get 16, because each physical core is presenting itself as two cores to my operating system.</p>
<p>So, how you you think about this?</p>
<ul class="simple">
<li><p>In most contexts (i.e. if you’re not shoping for hardware), expect the terms “cores” and “processors” to both be used to refer to independent processing cores.</p></li>
<li><p>Don’t worry about whether they’re distributed across two different physical chips or not – all that matters is the number of cores on your computer.</p></li>
<li><p>On most computers, expect the operating system to think that you have twice as many cores (sometimes referred to as “logical cores”) as you have actual “physical cores”, but expect your performance to reflect the number of physical cores you actually have.</p></li>
</ul>
</div>
<div class="section" id="Types-of-Parallelism">
<h2>Types of Parallelism<a class="headerlink" href="#Types-of-Parallelism" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Multi-processing">
<h3>Multi-processing<a class="headerlink" href="#Multi-processing" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="Multi-threading">
<h3>Multi-threading<a class="headerlink" href="#Multi-threading" title="Permalink to this headline">¶</a></h3>
<p>DANGER! HERE BE DRAGONS! RACE CONDITIONS!</p>
</div>
</div>
<div class="section" id="How-do-I-paralleize?">
<h2>How do I paralleize?<a class="headerlink" href="#How-do-I-paralleize?" title="Permalink to this headline">¶</a></h2>
<p>joblib</p>
<p><a class="reference external" href="https://sebastianraschka.com/Articles/2014_multiprocessing.html">https://sebastianraschka.com/Articles/2014_multiprocessing.html</a></p>
<p><a class="reference external" href="https://wiki.python.org/moin/ParallelProcessing">https://wiki.python.org/moin/ParallelProcessing</a></p>
<p>dask</p>
<p>Further reading / resources:</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=zX4ZNfvw1cw">https://www.youtube.com/watch?v=zX4ZNfvw1cw</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Practical DS</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="class_schedule.html">CLASS SCHEDULE</a></li>
</ul>
<p class="caption"><span class="caption-text">PYTHON &amp; PANDAS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="setup_environment.html">Setting Up Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="managing_python_packages.html">Managing Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="python_v_r.html">Python / R Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="vars_v_objects.html">Python: Vars v Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="ints_and_floats.html">Numbers in Computers</a></li>
<li class="toctree-l1"><a class="reference internal" href="pandas_series.html">Pandas 1: Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="pandas_dataframes.html">Pandas 2: DataFrames</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting_part1.html">Plotting, Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting_part2.html">Plotting, Advanced</a></li>
<li class="toctree-l1"><a class="reference internal" href="views_and_copies_in_pandas.html">Pandas 3: Views</a></li>
</ul>
<p class="caption"><span class="caption-text">OTHER TOOLS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="command_line_part1.html">Command Line, Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="command_line_part2.html">Command Line, Advanced</a></li>
<li class="toctree-l1"><a class="reference internal" href="jupyter.html">Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="git_and_github.html">Git and Github</a></li>
</ul>
<p class="caption"><span class="caption-text">SKILLS</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_help.html">Getting Help Online</a></li>
<li class="toctree-l1"><a class="reference internal" href="what_is_big_data.html">What is Big Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="big_data_strategies.html">Working with Big Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_understanding.html">Understanding Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_solutions.html">Solving Performance Probs</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parallel Computing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#What-is-Parallelism">What <em>is</em> Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Why-is-Paralleism-important?">Why is Paralleism important?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Limits-of-Parallelism">Limits of Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Vocabulary">Vocabulary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Types-of-Parallelism">Types of Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="#How-do-I-paralleize?">How do I paralleize?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="defensive_programming.html">Defensive Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow.html">Workflow Management</a></li>
</ul>
<p class="caption"><span class="caption-text">OTHER</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="not_a_mids_student.html">Not a MIDS Student?</a></li>
<li class="toctree-l1"><a class="reference internal" href="cheatsheets.html">Cheat Sheets</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="performance_solutions.html" title="previous chapter">Solving Performance Issues</a></li>
      <li>Next: <a href="defensive_programming.html" title="next chapter">Defensive Programming</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Nick Eubank.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.2.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/parallelism.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-133829453-1']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>